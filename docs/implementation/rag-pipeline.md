# RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ê°€ì´ë“œ

> **ëª©í‘œ**: â€œì—…ë¡œë“œ â†’ ì„ë² ë”© â†’ ê²€ìƒ‰ â†’ ë‹µë³€â€ í”Œë¡œìš°ë¥¼ FastAPI + LangChain + Chromaë¡œ ì²˜ìŒë¶€í„° ëê¹Œì§€ êµ¬ì¶•í•œë‹¤.

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

| Step | ê²°ê³¼                               | í•µì‹¬ ì—­ëŸ‰                                 |
| ---- | ---------------------------------- | ----------------------------------------- |
| 1    | ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ í‘œì¤€ í¬ë§·ìœ¼ë¡œ íŒŒì‹± | íŒŒì¼ íŒŒì„œ êµ¬ì„±, ë©”íƒ€ë°ì´í„° ê´€ë¦¬           |
| 2    | í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„ë¦¬í•˜ê³  ì„ë² ë”©    | LangChain TextSplitter & OpenAI Embedding |
| 3    | ë²¡í„° DBì— ì˜êµ¬ ì €ì¥                | Chroma ì»¬ë ‰ì…˜ ê´€ë¦¬, ì¬ìƒ‰ì¸ ì „ëµ           |
| 4    | ìœ ì‚¬ë„ ê²€ìƒ‰ + GPT ì‘ë‹µ ìƒì„±        | `score_threshold`, í”„ë¡¬í”„íŠ¸ ê°€ë“œë ˆì¼      |
| 5    | ìš”ì²­/ì‘ë‹µ/ë¹„ìš© ë¡œê¹…                | ë¹„ìš© ê³„ì‚°, JSON/DB ë¡œê¹…, í’ˆì§ˆ ì§€í‘œ        |

---

## ğŸ› ï¸ ì‚¬ì „ ì¤€ë¹„

| í•­ëª©        | ë‚´ìš©                                                                                                            |
| ----------- | --------------------------------------------------------------------------------------------------------------- |
| í™˜ê²½        | Python 3.10+, Git, VS Code/PyCharm                                                                              |
| íŒ¨í‚¤ì§€      | `pip install -r requirements.txt` (ì°¸ê³ : [`appendix/setup-requirements.md`](../appendix/setup-requirements.md)) |
| í™˜ê²½ë³€ìˆ˜    | `.env`ì— `OPENAI_API_KEY`, `VECTOR_DB_PATH`, `CHUNK_SIZE`, `CHUNK_OVERLAP`                                      |
| ìƒ˜í”Œ ë°ì´í„° | `data/`ì— PDF/Docx/CSV ê° 1ê°œ ì´ìƒ                                                                              |

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

---

## ğŸ’» ìƒ˜í”Œ ì½”ë“œ ì‹œì‘ì 

```python
# app/pipelines.py
from langchain.text_splitter import RecursiveCharacterTextSplitter
from app.vector_store import vector_client
from app.parsers import parse_document


async def process_upload(file) -> str:
    text, metadata = parse_document(file)
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=600,
        chunk_overlap=120,
    )
    chunks = splitter.create_documents([text], metadatas=[metadata])
    vector_client.add_documents(chunks)
    return metadata["doc_id"]
```

```python
# app/retriever.py
from app.vector_store import vector_client
from app.llm import build_prompt_and_ask

async def retrieve_answer(question: str) -> dict:
    docs = vector_client.similarity_search(question, k=5, score_threshold=0.75)
    if not docs:
        return {
            "answer": "ìë£Œì—ì„œ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê´€ë ¨ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.",
            "sources": [],
        }
    return await build_prompt_and_ask(question, docs)
```

---

## ğŸ”„ ë‹¨ê³„ë³„ ì‹¤ìŠµ ê°€ì´ë“œ

### 1. ë¬¸ì„œ ì—…ë¡œë“œ & íŒŒì‹±

```python
# app/parsers/pdf.py
from pypdf import PdfReader

def parse_pdf(file) -> tuple[str, dict]:
    reader = PdfReader(file)
    text = "\n\n".join(page.extract_text() for page in reader.pages)
    metadata = {
        "doc_id": file.filename,
        "title": file.filename,
        "source_path": f"data/uploads/{file.filename}",
        "page_count": len(reader.pages),
    }
    return text, metadata
```

- íŒŒì¼ í™•ì¥ìì— ë”°ë¼ íŒŒì„œ ë¼ìš°íŒ… (`app/parsers/__init__.py`)
- ì—…ë¡œë“œ ì‹œ `data/uploads/{uuid}` ê²½ë¡œì— ì €ì¥ í›„ íŒŒì„œ í˜¸ì¶œ
- ë©”íƒ€ë°ì´í„°ì— `access_level`, `team` í•„ë“œë¥¼ ì¶”ê°€í•´ Week 6 ê¶Œí•œ ê¸°ëŠ¥ê³¼ ì—°ê³„

### 2. ì²­í¬ ë¶„í• 

| ì„¤ì •            | ê¸°ë³¸ê°’                    | ì¡°ì • ê°€ì´ë“œ                                        |
| --------------- | ------------------------- | -------------------------------------------------- |
| `chunk_size`    | 600                       | ë¬¸ì„œê°€ ê¸¸ìˆ˜ë¡ ì¦ê°€, GPT 4o mini ê¸°ì¤€ 800 ì´í•˜ ì¶”ì²œ |
| `chunk_overlap` | 120                       | ì •ë³´ ì†ì‹¤ì´ ìˆìœ¼ë©´ 150ê¹Œì§€ í™•ì¥                    |
| `separators`    | `["\n\n", "\n", " ", ""]` | ì œëª©, ë¬¸ë‹¨ ë‹¨ìœ„ ë¶„ë¦¬ì— í™œìš©                        |

```python
splitter = RecursiveCharacterTextSplitter(
    chunk_size=settings.CHUNK_SIZE,
    chunk_overlap=settings.CHUNK_OVERLAP,
    separators=["\n\n", "\n", " ", ""],
)
```

### 3. ì„ë² ë”© ìƒì„±

```python
# app/embeddings.py
from langchain_openai import OpenAIEmbeddings

embedding = OpenAIEmbeddings(model="text-embedding-3-small")

def embed_texts(chunks):
    vectors = embedding.embed_documents([c.page_content for c in chunks])
    return vectors
```

- í† í° ê¸¸ì´ë¥¼ `tiktoken`ìœ¼ë¡œ ì¸¡ì •í•´ ë¹„ìš© ì¶”ì •
- í–¥í›„ ë¹„ìš© ì ˆê°ì„ ìœ„í•´ `sentence-transformers` ê¸°ë°˜ ë¡œì»¬ ëª¨ë¸ë¡œ êµì²´ ê°€ëŠ¥

### 4. ë²¡í„° ìƒ‰ì¸

```python
# app/vector_store.py
from langchain.vectorstores import Chroma
from app.embeddings import embedding
from app.config import settings

vector_client = Chroma(
    collection_name="rag_documents",
    embedding_function=embedding,
    persist_directory=settings.vector_db_path,
)
```

- ì¬ìƒ‰ì¸ ì‹œ `vector_client.delete(where={"doc_id": doc_id})`ë¡œ ê¸°ì¡´ ë°ì´í„° ì •ë¦¬
- `persist()` í˜¸ì¶œ í›„ `vector_db_path` í´ë”ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸

### 5. ê²€ìƒ‰ & ì‘ë‹µ ìƒì„±

```python
# app/llm.py
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)

async def build_prompt_and_ask(question: str, docs):
    context = "\n\n".join(
        f"[{doc.metadata.get('title','ë¬¸ì„œ')} | p.{doc.metadata.get('page','?')}] {doc.page_content}"
        for doc in docs
    )
    messages = [
        SystemMessage(content=(
            "ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ Q&A ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
            "ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì•ˆì—ì„œë§Œ ë‹µë³€í•˜ê³ , ë§ˆì§€ë§‰ì— ì¶œì²˜ ëª©ë¡ì„ bulletë¡œ ë‚˜ì—´í•˜ì„¸ìš”.\n"
            "ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ë‹µë³€ ëŒ€ì‹  ë¬¸ì„œ ì—…ë¡œë“œë¥¼ ìš”ì²­í•˜ì„¸ìš”."
        )),
        HumanMessage(content=f"ì§ˆë¬¸: {question}\n\nì»¨í…ìŠ¤íŠ¸:\n{context}"),
    ]
    completion = await llm.apredict_messages(messages)
    return {
        "answer": completion.content,
        "sources": [
            {
                "title": doc.metadata.get("title"),
                "page": doc.metadata.get("page"),
                "url": doc.metadata.get("source_url"),
            }
            for doc in docs
        ],
    }
```

### 6. ì‘ë‹µ ë¡œê¹… & ë¹„ìš© ê³„ì‚°

```python
# app/logging.py
from datetime import datetime
from decimal import Decimal

PROMPT_PRICE = Decimal("0.0005")  # per 1K tokens
COMPLETION_PRICE = Decimal("0.0015")

def calc_cost(token_in: int, token_out: int) -> Decimal:
    return (Decimal(token_in) / 1000 * PROMPT_PRICE) + (
        Decimal(token_out) / 1000 * COMPLETION_PRICE
    )

def log_response(payload: dict):
    payload["created_at"] = datetime.utcnow().isoformat()
    with open("logs/responses.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(payload, ensure_ascii=False) + "\n")
```

Week 6 ì´í›„ì—ëŠ” SQLAlchemy ëª¨ë¸ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•´ `/admin` ëŒ€ì‹œë³´ë“œì—ì„œ ì‹œê°í™”í•©ë‹ˆë‹¤.

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] íŒŒì¼ ì—…ë¡œë“œ í›„ `vector_client.count()`ê°€ 0ë³´ë‹¤ í¬ë‹¤.
- [ ] `/ask` ì‘ë‹µì— `sources` ë°°ì—´ì´ í¬í•¨ëœë‹¤.
- [ ] `score_threshold` ì´í•˜ì¼ ë•Œ â€œê·¼ê±° ì—†ìŒâ€ ë©”ì‹œì§€ê°€ ì¶œë ¥ëœë‹¤.
- [ ] `logs/responses.jsonl`ì— `token_in/out`, `cost`ê°€ ê¸°ë¡ëœë‹¤.
- [ ] `scripts/evaluate.py`ë¡œ ì •ë‹µë¥ /ê·¼ê±° ì¼ì¹˜ìœ¨ì„ ì¸¡ì •í–ˆë‹¤.

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ & í’ˆì§ˆ ê´€ë¦¬

| í…ŒìŠ¤íŠ¸        | ëª©ì                          | ëª…ë ¹                                                 |
| ------------- | ---------------------------- | ---------------------------------------------------- |
| ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ | ì—…ë¡œë“œ â†’ ì§ˆë¬¸ íë¦„ ì •ìƒ ë™ì‘ | `pytest tests/test_pipeline.py -m smoke`             |
| í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ | ì •í™•ë„Â·ê·¼ê±° ì¼ì¹˜ìœ¨ í™•ì¸      | `python scripts/evaluate.py --dataset data/eval.csv` |
| ë¶€í•˜ í…ŒìŠ¤íŠ¸   | ë‹¤ì¤‘ ìš”ì²­ ëŒ€ì‘               | `locust -f scripts/locustfile.py` (ì„ íƒ)             |

CI ì˜ˆì‹œ:
```yaml
- name: Pipeline Tests
  run: |
    pip install -r requirements.txt
    VECTOR_DB_PATH=./tmp/chroma pytest tests/ -m "pipeline"
```

---

## ğŸ” ìš´ì˜ íŒ

- ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ í›„ì—ëŠ” ë°˜ë“œì‹œ ì¬ìƒ‰ì¸ & ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
- Chroma í´ë”ëŠ” ì£¼ 1íšŒ ì´ìƒ ë°±ì—… (ZIP â†’ S3/Google Drive)
- ë¬¸ì„œ ë²„ì „ ê´€ë¦¬(Revision í•„ë“œ)ë¥¼ ì¶”ê°€í•´ ë¡¤ë°±ì„ ëŒ€ë¹„
- ìì£¼ ì§ˆë¬¸ë˜ëŠ” ë¬¸ì„œëŠ” `sources` í•„ë“œì— ë§í¬ë¥¼ ì¶”ê°€í•´ ì‚¬ìš©ìê°€ ë°”ë¡œ ì—´ëŒ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.

---

## ğŸ“š ì°¸ê³  & ë‹¤ìŒ í•™ìŠµ

- [LangChain í…ìŠ¤íŠ¸ ë¶„í•  ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/docs/modules/data_connection/document_transformers/)
- [Chroma ë¬¸ì„œ](https://docs.trychroma.com/)
- [OpenAI ê°€ê²©í‘œ](https://openai.com/pricing)
- ê¶Œí•œ/ë¡œê·¸ í™•ì¥ì€ [`implementation/web-admin.md`](web-admin.md)ë¥¼ ì°¸ê³ 
- ì±„ë„ ì—°ë™ì€ [`implementation/bots.md`](bots.md)ì—ì„œ ì´ì–´ì„œ ì§„í–‰

ë¬¸ì œê°€ ë°œìƒí•˜ë©´ [`appendix/troubleshooting.md`](../appendix/troubleshooting.md)ë¥¼ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”.

