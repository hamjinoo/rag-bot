from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from typing import List, Tuple
import os
from dotenv import load_dotenv

load_dotenv()

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
embedding = OpenAIEmbeddings(
    model="text-embedding-3-small",  # ë¹„ìš© ì ˆê°í˜•
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# Chroma ë²¡í„° DB í´ë¼ì´ì–¸íŠ¸
vector_client = Chroma(
    collection_name="rag_documents",
    embedding_function=embedding,
    persist_directory=os.getenv("VECTOR_DB_PATH", "./chroma"),
)

def add_documents(chunks: List[Document], clear_existing: bool = False):
    """
    ì²­í¬ë¥¼ ë²¡í„° DBì— ì €ì¥
    
    Args:
        chunks: ì €ì¥í•  Document ë¦¬ìŠ¤íŠ¸
        clear_existing: ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì—¬ë¶€ (í…ŒìŠ¤íŠ¸ ì‹œ ì¤‘ë³µ ë°©ì§€ìš©)
    """
    global vector_client  # í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì— global ì„ ì–¸
    
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (í…ŒìŠ¤íŠ¸ ì‹œ ì¤‘ë³µ ë°©ì§€)
    if clear_existing:
        try:
            # ChromaDB ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
            vector_client.delete_collection()
            # ìƒˆë¡œ ìƒì„±
            vector_client = Chroma(
                collection_name="rag_documents",
                embedding_function=embedding,
                persist_directory=os.getenv("VECTOR_DB_PATH", "./chroma"),
            )
            print("ğŸ—‘ï¸  ê¸°ì¡´ ë²¡í„° DB ë°ì´í„° ì‚­ì œë¨")
        except Exception as e:
            print(f"âš ï¸  ì»¬ë ‰ì…˜ ì‚­ì œ ì‹¤íŒ¨ (ì´ë¯¸ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ): {e}")
    
    vector_client.add_documents(chunks)
    vector_client.persist()
    print(f"âœ… {len(chunks)}ê°œ ì²­í¬ë¥¼ ë²¡í„° DBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

def search_documents(query: str, k: int = 5, score_threshold: float = None):
    """
    ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
    
    Args:
        query: ê²€ìƒ‰ ì§ˆë¬¸
        k: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
        score_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜ (Noneì´ë©´ í•„í„°ë§ ì•ˆ í•¨, 0.0~1.0 ë²”ìœ„)
                        ê¸°ë³¸ê°’ì€ None (ëª¨ë“  ê²°ê³¼ ë°˜í™˜)
    
    Returns:
        List[Tuple[Document, float]]: (ë¬¸ì„œ, ìœ ì‚¬ë„ ì ìˆ˜) ë¦¬ìŠ¤íŠ¸
    """
    # ChromaDBì˜ similarity_search_with_scoreëŠ” ê±°ë¦¬(distance)ë¥¼ ë°˜í™˜
    # ì½”ì‚¬ì¸ ê±°ë¦¬: 0 (ì™„ì „íˆ ë™ì¼) ~ 2 (ì™„ì „íˆ ë°˜ëŒ€)
    # L2 ê±°ë¦¬: 0 ì´ìƒì˜ ê°’ (ì‘ì„ìˆ˜ë¡ ìœ ì‚¬)
    results = vector_client.similarity_search_with_score(
        query=query,
        k=k,
    )
    
    # ê±°ë¦¬ ì ìˆ˜ë¥¼ ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë³€í™˜
    # ChromaDBëŠ” ê¸°ë³¸ì ìœ¼ë¡œ L2 ê±°ë¦¬ë¥¼ ì‚¬ìš©
    # OpenAI ì„ë² ë”©ì€ ì •ê·œí™”ëœ ë²¡í„°ì´ë¯€ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì í•©
    # í•˜ì§€ë§Œ ChromaDBëŠ” L2 ê±°ë¦¬ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ì´ë¥¼ ì ì ˆíˆ ë³€í™˜í•´ì•¼ í•¨
    
    normalized_results = []
    seen_content = set()  # ì¤‘ë³µ ì œê±°ìš©
    
    # ChromaDBëŠ” L2 ê±°ë¦¬ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, ì •ê·œí™”ëœ ë²¡í„°ì˜ ê²½ìš°
    # ê±°ë¦¬ ë²”ìœ„ëŠ” 0 ~ sqrt(2) â‰ˆ 1.414
    # ì‹¤ì œ ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê±°ë¦¬ ë³€í™˜ ìµœì í™”
    
    for doc, distance in results:
        # ì¤‘ë³µ ì œê±°: ë™ì¼í•œ ë‚´ìš©ì˜ ë¬¸ì„œëŠ” ê±´ë„ˆë›°ê¸°
        content_hash = hash(doc.page_content[:100])  # ì²« 100ìë¡œ ì¤‘ë³µ íŒë‹¨
        if content_hash in seen_content:
            continue
        seen_content.add(content_hash)
        
        # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
        # OpenAI ì„ë² ë”©(text-embedding-3-small)ì€ ì •ê·œí™”ëœ ë²¡í„°ë¥¼ ë°˜í™˜
        # ì •ê·œí™”ëœ ë²¡í„°ì˜ L2 ê±°ë¦¬ ë²”ìœ„: 0 ~ sqrt(2) â‰ˆ 1.414
        # 
        # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼: ìœ ì‚¬ë„ 0.318~0.383 â†’ ê±°ë¦¬ ì•½ 0.9~1.1
        # ë” ë‚˜ì€ ë³€í™˜: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = 1 - (ê±°ë¦¬^2 / 2)
        # ë˜ëŠ” ë‹¨ìˆœ ì„ í˜•: similarity = max(0, 1 - distance / sqrt(2))
        
        # ë°©ë²• 1: ì •ê·œí™”ëœ ë²¡í„°ì˜ L2 ê±°ë¦¬ë¥¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ë³€í™˜
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = 1 - (L2ê±°ë¦¬^2 / 2) (ì •ê·œí™”ëœ ë²¡í„°ì˜ ê²½ìš°)
        max_distance = 1.414  # sqrt(2) for normalized vectors
        
        if distance <= max_distance:
            # ì •ê·œí™”ëœ ë²¡í„°ì˜ ê²½ìš°: similarity = 1 - (distance^2 / 2)
            # ë˜ëŠ” ì„ í˜• ë³€í™˜: similarity = 1 - (distance / max_distance)
            # ì‹¤í—˜ì ìœ¼ë¡œ ì œê³± ê³µì‹ì´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì œê³µ
            similarity = max(0.0, 1.0 - (distance * distance) / 2.0)
        else:
            # ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê²½ìš°: ì§€ìˆ˜ ê°ì‡ 
            similarity = max(0.0, 1.0 / (1.0 + distance))
        
        normalized_results.append((doc, similarity))
    
    # threshold í•„í„°ë§ (ì§€ì •ëœ ê²½ìš°)
    if score_threshold is not None and score_threshold > 0:
        filtered_results = [
            (doc, sim) for doc, sim in normalized_results 
            if sim >= score_threshold
        ]
        return filtered_results
    
    return normalized_results
